{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1958,
   "id": "f44e3916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Win-Loss Percentage_team1  SRS_team1  SOS_team1  Team Points_team1  \\\n",
      "0                         0.778       1.87      -5.01             2278.0   \n",
      "1                         0.800      22.91       6.71             2077.0   \n",
      "2                         0.840      13.82       4.65             2027.0   \n",
      "3                         0.760      14.42       7.24             1951.0   \n",
      "4                         0.667      14.61       7.74             1782.0   \n",
      "...                         ...        ...        ...                ...   \n",
      "1763                      0.640      19.12       9.72             1882.0   \n",
      "1764                      0.640      13.18       7.62             1837.0   \n",
      "1765                      0.760      13.12       4.37             1913.0   \n",
      "1766                      0.720      18.91       7.43             2031.0   \n",
      "1767                      0.760      17.99       9.74             1925.0   \n",
      "\n",
      "      Opponent Ponts_team1  Minutes Played_team1  FG_team1  FGA_team1  \\\n",
      "0                   2003.0                1095.0     742.0     1604.0   \n",
      "1                   1672.0                1000.0     718.0     1531.0   \n",
      "2                   1732.0                1010.0     735.0     1476.0   \n",
      "3                   1709.0                1010.0     706.0     1412.0   \n",
      "4                   1617.0                 960.0     630.0     1407.0   \n",
      "...                    ...                   ...       ...        ...   \n",
      "1763                1647.0                1005.0     697.0     1463.0   \n",
      "1764                1698.0                1015.0     651.0     1436.0   \n",
      "1765                1670.0                1005.0     661.0     1399.0   \n",
      "1766                1744.0                1025.0     737.0     1510.0   \n",
      "1767                1700.0                1005.0     721.0     1442.0   \n",
      "\n",
      "      FG%_team1  3P_team1  ...  ORB_team2  TRB_team2  AST_team2  STL_team2  \\\n",
      "0         0.463     223.0  ...      371.0     1038.0      330.0      182.0   \n",
      "1         0.469     197.0  ...      274.0      890.0      397.0      168.0   \n",
      "2         0.498     155.0  ...      188.0      708.0      363.0      165.0   \n",
      "3         0.500     201.0  ...      217.0      831.0      340.0      149.0   \n",
      "4         0.448     177.0  ...      263.0      940.0      299.0      141.0   \n",
      "...         ...       ...  ...        ...        ...        ...        ...   \n",
      "1763      0.476     167.0  ...      315.0     1021.0      317.0      110.0   \n",
      "1764      0.453     198.0  ...      321.0      958.0      327.0      182.0   \n",
      "1765      0.472     148.0  ...      180.0      800.0      479.0      179.0   \n",
      "1766      0.488     266.0  ...      297.0      830.0      296.0      141.0   \n",
      "1767      0.500     152.0  ...      285.0      918.0      346.0      211.0   \n",
      "\n",
      "      BLK_team2  TOV_team2  PF_team2  team1_location_Away  \\\n",
      "0          73.0      333.0     479.0                 True   \n",
      "1         133.0      321.0     419.0                False   \n",
      "2          96.0      299.0     413.0                 True   \n",
      "3          94.0      251.0     377.0                False   \n",
      "4          86.0      283.0     489.0                False   \n",
      "...         ...        ...       ...                  ...   \n",
      "1763       99.0      264.0     354.0                False   \n",
      "1764      115.0      325.0     392.0                 True   \n",
      "1765       81.0      259.0     412.0                 True   \n",
      "1766       81.0      296.0     395.0                False   \n",
      "1767       68.0      271.0     450.0                False   \n",
      "\n",
      "      team1_location_Home  team1_location_Neutral  \n",
      "0                   False                   False  \n",
      "1                    True                   False  \n",
      "2                   False                   False  \n",
      "3                   False                    True  \n",
      "4                    True                   False  \n",
      "...                   ...                     ...  \n",
      "1763                 True                   False  \n",
      "1764                False                   False  \n",
      "1765                False                   False  \n",
      "1766                 True                   False  \n",
      "1767                 True                   False  \n",
      "\n",
      "[1768 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import r2_score, explained_variance_score\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# load in March Madness data, target is for regression, target2 is for classification\n",
    "df = pd.read_csv('MarchMadnessData2024.csv')\n",
    "target = df['margin']\n",
    "target2 = (df['margin'] > 0)\n",
    "\n",
    "# drop target column\n",
    "X = df.drop(columns = ['margin'])\n",
    "\n",
    "# shuffle the data set\n",
    "shuffled_indices = np.random.permutation(X.index)\n",
    "X = X.iloc[shuffled_indices].reset_index(drop=True)\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1959,
   "id": "265e49d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score = 0\n",
    " # shuffle the data set\n",
    "shuffled_indices = np.random.permutation(X.index)\n",
    "X = X.iloc[shuffled_indices].reset_index(drop=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_norm = scaler.fit_transform(X)\n",
    "\n",
    "for components in range(13, 47): \n",
    "    # create a pca model for each number of components\n",
    "    pca = PCA(n_components = components)\n",
    "    X_pca = pca.fit_transform(X_norm)\n",
    "\n",
    "    # calculate explained variance\n",
    "    explained_variance = sum(pca.explained_variance_ratio_)\n",
    "    \n",
    "    # split data into train and test\n",
    "    trainX, testX, trainY, testY = train_test_split(X_pca, target2, test_size = 0.2)\n",
    "    scorerVar = make_scorer(f1_score, pos_label = 1)\n",
    "\n",
    "    # create and fit svm model, print initial score\n",
    "    svm_model = SVC()\n",
    "    svm_model.fit(X_pca, target2)\n",
    "    svm_model.predict(testX)\n",
    "    print(\"Initial score for svm is \", svm_model.score(testX, testY), \" for \", components, \" components\")\n",
    "    \n",
    "    # get the cross value score for svm, if it's better than the max score then set it to max\n",
    "    svm_cv_score = cross_val_score(svm_model, X_pca, target2, cv = 10, scoring = scorerVar)\n",
    "    print(\"Cross Validation Score for SVM: \", np.mean(svm_cv_score), \" for \", components, \" components\")\n",
    "    print()\n",
    "    if np.mean(svm_cv_score) > max_score:\n",
    "        max_score = np.mean(svm_cv_score)\n",
    "        print(\"New max: \", max_score, \" at \", components, \"components\")\n",
    "    \n",
    "    # repeat with logistic regression model\n",
    "    lr_model = LogisticRegression()\n",
    "    lr_model.fit(trainX, trainY)\n",
    "    lr_model.predict(testX)\n",
    "    print(\"Initial score for LogRegression is \", lr_model.score(testX, testY), \" for \", components, \" components\")\n",
    "\n",
    "    lr_cv_score = cross_val_score(lr_model, X_pca, target2, cv = 7, scoring = scorerVar)\n",
    "    print(\"Cross Validation Score for LogRegression: \", np.mean(lr_cv_score), \" for \", components, \"components\")\n",
    "    print()\n",
    "    if np.mean(lr_cv_score) > max_score:\n",
    "        max_score = np.mean(lr_cv_score)\n",
    "        print(\"New max: \", max_score, \" at \", components, \"components\")\n",
    "    \n",
    "# # Best Score: Logistic Regression at 25 components: cv_score = 0.8410353628455827"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4098bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "36\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "team1 = [\n",
    "        'Connecticut', 'Fla Atlantic', 'San Diego St', 'Auburn', 'BYU', 'Illinois', 'Wash State', 'Iowa St', \n",
    "        'North Carolina', 'North Carolina', 'Miss State', 'St Marys', 'Alabama', 'Clemson', 'Baylor', 'Dayton', 'Arizona', \n",
    "        'Houston', 'Nebraska', 'Wisconsin', 'Duke', 'Texas Tech', 'Kentucky', 'Florida', 'Florida', 'Marquette', \n",
    "        'Purdue', 'Purdue', 'Utah St', 'Gonzaga', 'Kansas', 'S Carolina', 'Creighton', 'Texas', 'Texas', 'Tennessee'\n",
    "        ]\n",
    "\n",
    "team2 = [\n",
    "        'Stetson', 'Northwestern', 'UAB', 'Yale', 'Duquesne', 'Morehead St', 'Drake', 'S Dakota St', \n",
    "        'Wagner', 'Howard', 'Michigan St', 'Grd Canyon', 'Col Charlestn', 'New Mexico', 'Colgate', 'Nevada', 'Lg Beach St', \n",
    "        'Longwood', 'Texas A&M', 'James Mad', 'Vermont', 'NC State', 'Oakland', 'Boise St', 'Colorado', 'W Kentucky', \n",
    "        'Montana St', 'Grambling St', 'TX Christian', 'McNeese St', 'Samford', 'Oregon', 'Akron', 'Virginia', 'Colorado St', 'St Peters'\n",
    "        ]\n",
    "\n",
    "location = ['neutral','home','away','neutral','neutral','neutral','neutral','neutral','neutral','neutral','neutral','neutral','neutral',\n",
    "            'neutral','neutral','neutral','neutral','neutral','neutral','neutral','neutral','neutral','neutral','neutral','neutral','neutral','neutral'\n",
    "             'neutral','neutral','neutral','neutral','neutral','neutral','neutral','neutral','neutral','neutral'\n",
    "        ]\n",
    "# fill in teams and locations\n",
    "print(len(team1))\n",
    "print(len(team2))\n",
    "print(len(location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1961,
   "id": "00d74ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Score:  0.8410343602497082\n",
      "40\n",
      "             team1           team2  predictions\n",
      "0      Connecticut    Northwestern         True\n",
      "1           Auburn    San Diego St         True\n",
      "2         Illinois             BYU         True\n",
      "3          Iowa St      Wash State         True\n",
      "4   North Carolina      Miss State         True\n",
      "5          Alabama        St Marys         True\n",
      "6           Baylor      New Mexico         True\n",
      "7          Arizona          Nevada         True\n",
      "8          Houston        Nebraska         True\n",
      "9             Duke       James Mad         True\n",
      "10        Kentucky        NC State         True\n",
      "11       Marquette         Florida         True\n",
      "12          Purdue         Utah St         True\n",
      "13          Kansas         Gonzaga         True\n",
      "14      S Carolina           Akron         True\n",
      "15       Tennessee           Texas         True\n",
      "16       Tennessee       Tennessee         True\n",
      "17       Tennessee       Tennessee         True\n",
      "18       Tennessee       Tennessee         True\n",
      "19          Auburn    Northwestern         True\n",
      "20         Iowa St        Illinois         True\n",
      "21  North Carolina        St Marys         True\n",
      "22         Arizona      New Mexico         True\n",
      "23         Houston       James Mad         True\n",
      "24       Marquette        Kentucky         True\n",
      "25          Purdue          Kansas         True\n",
      "26       Tennessee      S Carolina         True\n",
      "27       Tennessee       Tennessee         True\n",
      "28       Tennessee       Tennessee         True\n",
      "29       Tennessee       Tennessee         True\n",
      "30    Northwestern         Iowa St         True\n",
      "31         Arizona  North Carolina         True\n",
      "32       Marquette         Houston         True\n",
      "33          Kansas       Tennessee         True\n",
      "34       Tennessee       Tennessee         True\n",
      "35       Tennessee       Tennessee         True\n",
      "36       Tennessee       Tennessee         True\n",
      "37         Arizona         Iowa St         True\n",
      "38       Tennessee         Houston         True\n",
      "39         Iowa St         Houston         True\n"
     ]
    }
   ],
   "source": [
    "data_dump = pd.read_csv('march_madness_data_dump.csv')\n",
    "\n",
    "df = pd.DataFrame({'team1':team1, 'team2':team2, 'team1_location':location})\n",
    "\n",
    "# merge data dump with game data to predict\n",
    "merge1 = pd.merge(df, data_dump, left_on = 'team1', right_on = 'School', how = 'left')\n",
    "final = pd.merge(merge1, data_dump, left_on = 'team2', right_on = 'School', how = 'left', suffixes = ('_team1', '_team2'))\n",
    "\n",
    "# use get_dummies() on team1_location, so that classification can be done \n",
    "final = pd.get_dummies(final, columns = ['team1_location'])\n",
    "\n",
    "# remove all rows containing null or empty values\n",
    "final = final.drop(columns = ['team1', 'team2', 'Rk_team1', 'Rk_team2', 'School_team1', 'School_team2'])\n",
    "\n",
    "# MinMaxScalar was found to be the best normalizer option\n",
    "scaler = MinMaxScaler()\n",
    "final_norm = scaler.fit_transform(final)\n",
    "X_norm = scaler.fit_transform(X)\n",
    "\n",
    "# pca with 25 components was the best option\n",
    "pca = PCA(n_components = 25)\n",
    "final_pca = pca.fit_transform(final_norm)\n",
    "X_pca = pca.fit_transform(X_norm)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, target2, test_size=0.25)\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Create and fit LogRegression model\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# check the cross value score\n",
    "scorerVar = make_scorer(f1_score, pos_label = 1)\n",
    "lr_cv_score = cross_val_score(lr_model, X_pca, target2, cv = 10, scoring = scorerVar)\n",
    "print(\"Cross Val Score: \", np.mean(lr_cv_score))\n",
    "\n",
    "# predictions will output whether or not team1 wins each game\n",
    "predictions = lr_model.predict(final_pca)\n",
    "\n",
    "print(len(predictions))\n",
    "print(pd.DataFrame({'team1':team1, 'team2':team2, 'predictions':predictions}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fe6629",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
