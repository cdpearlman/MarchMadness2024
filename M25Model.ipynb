{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# load in March Madness data, target is for regression, target2 is for classification\n",
    "df = pd.read_csv('MarchMadnessData2024.csv')\n",
    "df['team_1_win'] = (df['margin'] > 0).astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNModel(X_train, y_train, X_test, y_test):\n",
    "    # Build the neural network model\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "    # Evaluate model performance\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    with open(\"results.txt\", \"a\") as file:\n",
    "        file.write(f\"NN Test Accuracy: {accuracy:.4f} \\n\")\n",
    "\n",
    "    # Predict probabilities for new games\n",
    "    predictions = model.predict(X_test)\n",
    "    predicted_labels = (predictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def XGBoost(X_train, y_train, X_test, y_test):\n",
    "    model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    with open(\"results.txt\", \"a\") as file:\n",
    "        file.write(f\"XGBoost Test Accuracy: {accuracy:.4f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['margin', 'team_1_win'])\n",
    "Y = df['team_1_win']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "methods = {\n",
    "    \"standard_scaling\": StandardScaler(),\n",
    "    \"normalization\": MinMaxScaler(),\n",
    "    \"pca_10\": PCA(n_components=10),  # Adjust components as needed\n",
    "    \"pca_5\": PCA(n_components=5)\n",
    "}\n",
    "\n",
    "# Perform train-test split and apply each preprocessing technique\n",
    "for method_name, processor in methods.items():\n",
    "    with open(\"results.txt\", \"a\") as file:\n",
    "        file.write(f\"Using {method_name} \\n\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Fit and transform only on training data, then apply the same transformation to test data\n",
    "    X_train_transformed = processor.fit_transform(X_train)\n",
    "    X_test_transformed = processor.transform(X_test)\n",
    "    \n",
    "    for i in range(5, 20):\n",
    "        with open(\"results.txt\", \"a\") as file:\n",
    "            file.write(f\"Num Components: {i} \\n\")\n",
    "        pca = PCA(n_components=i)\n",
    "        X_train = pca.fit_transform(X_train_transformed)\n",
    "        X_test = pca.fit_transform(X_test_transformed)\n",
    "\n",
    "        NNModel(X_train, y_train, X_test, y_test)\n",
    "        XGBoost(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model was XGBoost with 16 components and MinMaxScalar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
